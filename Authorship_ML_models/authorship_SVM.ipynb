{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "400966af-72cd-d1ac-7520-c18c850f59a2"
   },
   "source": [
    "In this notebook I search for the best classifier and its parameters for tweets multi-class classifications based on authorship attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "f9242b05-8556-5229-e3da-da453ccda0af"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "4931abf3-141e-afea-559c-01560cde768c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '10460KDNuggetsTweets.csv',\n",
       " 'AdamSavageTweets.csv',\n",
       " 'AllTweets.csv',\n",
       " 'BarackObama.csv',\n",
       " 'DonaldTrump2014-01-01To2016-10-14Tweets.csv',\n",
       " 'DonaldTrumpTweets.csv',\n",
       " 'FiveThirtyEightTweets.csv',\n",
       " 'HillaryClinton2014-01-01To2016-10-14Tweets.csv',\n",
       " 'HillaryClintonTweets.csv',\n",
       " 'KimKardashianTweets.csv',\n",
       " 'NeildeGrasseTysonTweets.csv',\n",
       " 'RichardDawkins.csv',\n",
       " 'ScottKelly.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the path to the folder containing CSV files\n",
    "folder_path = 'tweets/'\n",
    "os.listdir(folder_path)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "4931abf3-141e-afea-559c-01560cde768c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>retweet</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Oct 4</td>\n",
       "      <td>783396985093193728</td>\n",
       "      <td>/missyscheng/status/783396985093193728</td>\n",
       "      <td>False</td>\n",
       "      <td>#DataScience Basics: #DataMining vs. #Statisti...</td>\n",
       "      <td>various</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Oct 4</td>\n",
       "      <td>783381842024103936</td>\n",
       "      <td>/EXASOLAG/status/783381842024103936</td>\n",
       "      <td>False</td>\n",
       "      <td>How to Become a #Data Scientist – Part 1: http...</td>\n",
       "      <td>various</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Oct 4</td>\n",
       "      <td>783433625723252736</td>\n",
       "      <td>/TarasNovak/status/783433625723252736</td>\n",
       "      <td>False</td>\n",
       "      <td>@jesterxl @kdnuggets or just go with @tableau :)</td>\n",
       "      <td>various</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Oct 4</td>\n",
       "      <td>783428740453982208</td>\n",
       "      <td>/kdnuggets/status/783428740453982208</td>\n",
       "      <td>False</td>\n",
       "      <td>#Boston U. Online MS in Applied #Business #Ana...</td>\n",
       "      <td>various</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1h1 hour ago</td>\n",
       "      <td>787052623291641856</td>\n",
       "      <td>/kdnuggets/status/787052623291641856</td>\n",
       "      <td>False</td>\n",
       "      <td>#ICYMI Still Searching for ROI in #BigData Ana...</td>\n",
       "      <td>various</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173030</th>\n",
       "      <td>1214</td>\n",
       "      <td>24 Aug 2009</td>\n",
       "      <td>3506949420</td>\n",
       "      <td>/StationCDRKelly/status/3506949420</td>\n",
       "      <td>False</td>\n",
       "      <td>@karen4jazz thanks!</td>\n",
       "      <td>ScottKelly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173031</th>\n",
       "      <td>1215</td>\n",
       "      <td>23 Aug 2009</td>\n",
       "      <td>3505850138</td>\n",
       "      <td>/StationCDRKelly/status/3505850138</td>\n",
       "      <td>False</td>\n",
       "      <td>The HARDEST thing about this ISS training is h...</td>\n",
       "      <td>ScottKelly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173032</th>\n",
       "      <td>1216</td>\n",
       "      <td>23 Aug 2009</td>\n",
       "      <td>3500803828</td>\n",
       "      <td>/StationCDRKelly/status/3500803828</td>\n",
       "      <td>False</td>\n",
       "      <td>Eating breakfast at the Okura Frontier Hotel i...</td>\n",
       "      <td>ScottKelly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173033</th>\n",
       "      <td>1217</td>\n",
       "      <td>23 Aug 2009</td>\n",
       "      <td>3488056654</td>\n",
       "      <td>/StationCDRKelly/status/3488056654</td>\n",
       "      <td>False</td>\n",
       "      <td>I think you will find the comparison (and cont...</td>\n",
       "      <td>ScottKelly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173034</th>\n",
       "      <td>1218</td>\n",
       "      <td>23 Aug 2009</td>\n",
       "      <td>3488038099</td>\n",
       "      <td>/StationCDRKelly/status/3488038099</td>\n",
       "      <td>False</td>\n",
       "      <td>My first attempt at twittering. in Japan for r...</td>\n",
       "      <td>ScottKelly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173035 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0          date                  id  \\\n",
       "0                0         Oct 4  783396985093193728   \n",
       "1                1         Oct 4  783381842024103936   \n",
       "2                2         Oct 4  783433625723252736   \n",
       "3                3         Oct 4  783428740453982208   \n",
       "4                4  1h1 hour ago  787052623291641856   \n",
       "...            ...           ...                 ...   \n",
       "173030        1214   24 Aug 2009          3506949420   \n",
       "173031        1215   23 Aug 2009          3505850138   \n",
       "173032        1216   23 Aug 2009          3500803828   \n",
       "173033        1217   23 Aug 2009          3488056654   \n",
       "173034        1218   23 Aug 2009          3488038099   \n",
       "\n",
       "                                          link  retweet  \\\n",
       "0       /missyscheng/status/783396985093193728    False   \n",
       "1          /EXASOLAG/status/783381842024103936    False   \n",
       "2        /TarasNovak/status/783433625723252736    False   \n",
       "3         /kdnuggets/status/783428740453982208    False   \n",
       "4         /kdnuggets/status/787052623291641856    False   \n",
       "...                                        ...      ...   \n",
       "173030      /StationCDRKelly/status/3506949420    False   \n",
       "173031      /StationCDRKelly/status/3505850138    False   \n",
       "173032      /StationCDRKelly/status/3500803828    False   \n",
       "173033      /StationCDRKelly/status/3488056654    False   \n",
       "173034      /StationCDRKelly/status/3488038099    False   \n",
       "\n",
       "                                                     text      author  \\\n",
       "0       #DataScience Basics: #DataMining vs. #Statisti...     various   \n",
       "1       How to Become a #Data Scientist – Part 1: http...     various   \n",
       "2        @jesterxl @kdnuggets or just go with @tableau :)     various   \n",
       "3       #Boston U. Online MS in Applied #Business #Ana...     various   \n",
       "4       #ICYMI Still Searching for ROI in #BigData Ana...     various   \n",
       "...                                                   ...         ...   \n",
       "173030                                @karen4jazz thanks!  ScottKelly   \n",
       "173031  The HARDEST thing about this ISS training is h...  ScottKelly   \n",
       "173032  Eating breakfast at the Okura Frontier Hotel i...  ScottKelly   \n",
       "173033  I think you will find the comparison (and cont...  ScottKelly   \n",
       "173034  My first attempt at twittering. in Japan for r...  ScottKelly   \n",
       "\n",
       "        Unnamed: 0.1  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  \n",
       "...              ...  \n",
       "173030           NaN  \n",
       "173031           NaN  \n",
       "173032           NaN  \n",
       "173033           NaN  \n",
       "173034           NaN  \n",
       "\n",
       "[173035 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each CSV file and read it into a DataFrame\n",
    "for csv_file in csv_files:\n",
    "    csv_file_path = os.path.join(folder_path, csv_file)\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Print the combined DataFrame\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0      0\n",
      "date            0\n",
      "id              0\n",
      "link            0\n",
      "retweet         0\n",
      "text            0\n",
      "author          0\n",
      "Unnamed: 0.1    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = combined_df\n",
    "df = df.dropna()\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "1c543c07-e26f-4228-5acf-bbdcf8c7ef89"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DonaldTrump</th>\n",
       "      <td>17216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NASA</th>\n",
       "      <td>15910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KimKardashian</th>\n",
       "      <td>10688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>various</th>\n",
       "      <td>10440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FiveThirtyEight</th>\n",
       "      <td>9761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BarackObama</th>\n",
       "      <td>6896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RichardDawkins</th>\n",
       "      <td>5839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdamSavage</th>\n",
       "      <td>4872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HillaryClinton</th>\n",
       "      <td>3356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deGrasseTyson</th>\n",
       "      <td>2428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScottKelly</th>\n",
       "      <td>1219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 counts\n",
       "author                 \n",
       "DonaldTrump       17216\n",
       "NASA              15910\n",
       "KimKardashian     10688\n",
       "various           10440\n",
       "FiveThirtyEight    9761\n",
       "BarackObama        6896\n",
       "RichardDawkins     5839\n",
       "AdamSavage         4872\n",
       "HillaryClinton     3356\n",
       "deGrasseTyson      2428\n",
       "ScottKelly         1219"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.groupby('author').size().rename('counts')).sort_values('counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "81a893de-edfb-159f-5059-65779054a592"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "#1000 random sample rows for each author\n",
    "df_new=pd.DataFrame()\n",
    "twts_train=pd.DataFrame()\n",
    "twts_test=pd.DataFrame()\n",
    "author_train=pd.DataFrame()\n",
    "author_test=pd.DataFrame()\n",
    "for a in df.author.unique():\n",
    "    rows = random.sample(list(df[df['author']==a].index), 1000)\n",
    "    df_temp = df.loc[rows]\n",
    "    # df_new=df_new.append(df_temp,ignore_index=True)   \n",
    "    df_new = pd.concat([df_new, df_temp], ignore_index=True)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df_temp.loc[:,['text']], df_temp.loc[:,['author']], test_size=0.2, random_state=42)\n",
    "    twts_train=twts_train.append(X_train, verify_integrity=False)\n",
    "    twts_test=twts_test.append(X_test, verify_integrity=False)\n",
    "    author_train=author_train.append(Y_train, verify_integrity=False)\n",
    "    author_test=author_test.append(Y_test, verify_integrity=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7def55a5-e597-b7c6-71f0-18d5f978b189"
   },
   "source": [
    "Train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "236a0f8f-3e91-23cd-8883-0a3ade730438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8800 8800\n"
     ]
    }
   ],
   "source": [
    "print (len(twts_train),len(author_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3ac1ccff-ab8e-314e-c23b-43eb5a3c9381"
   },
   "source": [
    "Test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "c7057861-fcb0-54cd-63ea-4323e4f4c79e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200 2200\n"
     ]
    }
   ],
   "source": [
    "print(len(twts_test),len(author_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "0fd35bab-22c8-1771-2f27-a30434a69a7f"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "def text_process(text):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Tokenizes and removes punctuation\n",
    "    3. Stems\n",
    "    4. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "\n",
    "    # tokenizing\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text_processed=tokenizer.tokenize(text)\n",
    "    \n",
    "    \n",
    "    # steming\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    \n",
    "    text_processed = [porter_stemmer.stem(word) for word in text_processed]\n",
    "    \n",
    "\n",
    "    return text_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "641896ba-81fa-9a7b-b3d6-a3487dcb7f24"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "277b05bb-1ef6-1d4f-ab3d-0e16811834e5"
   },
   "outputs": [],
   "source": [
    "ScoreSummaryByModel = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "3cef9c81-e97b-955f-5e1e-1b6037ad571e"
   },
   "outputs": [],
   "source": [
    "def PredictionEvaluation(author_test_b,author_predicted_b,target_names,comment):\n",
    "    Accuracy=accuracy_score(author_test_b,author_predicted_b)\n",
    "    #print (Accuracy)\n",
    "    Recall=recall_score(author_test_b, author_predicted_b, labels=[0,1,2,3], average='macro')\n",
    "    #print (Recall)\n",
    "    Precision=precision_score(author_test_b, author_predicted_b, labels=[0,1,2,3], average='macro')\n",
    "    #print (Precision)\n",
    "    F1=f1_score(author_test_b, author_predicted_b, labels=[0,1,2,3], average='macro')\n",
    "    #print (F1)\n",
    "    ScoreSummaryByModel.append([Accuracy,Recall,Precision,F1,comment])\n",
    "    print(classification_report(author_test_b, author_predicted_b, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "55f9396e-235f-d9f6-2735-bb2e9df87a74"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "33fd02cf-7ca6-9cb4-4c67-03624d8b11e0"
   },
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "ac725c81-8966-8bc9-7104-888bdec7905f"
   },
   "outputs": [],
   "source": [
    "ScoreSummaryByModelParams=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "1fdc617e-6678-0672-6e3e-dae4f51022c7"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "65ba7ad4-87be-ccd1-858c-fa873544782b"
   },
   "outputs": [],
   "source": [
    "def ModelParamsEvaluation (f_union,model,params,comment):\n",
    "    pipeline = Pipeline([\n",
    "    # Extract the text & text_coded\n",
    "    # Use FeatureUnion to combine the features from different vectorizers\n",
    "    ('union', f_union),\n",
    "    # Use a  classifier on the combined features\n",
    "    ('clf', model)\n",
    "    ])\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=params, verbose=1)\n",
    "    grid_search.fit(twts_train['text'], author_train['author'])\n",
    "    author_predicted = grid_search.predict(twts_test['text'])\n",
    "    lb = LabelBinarizer()\n",
    "    author_test_b = lb.fit_transform(author_test['author'])\n",
    "    author_predicted_b  = lb.fit_transform(author_predicted)\n",
    "    #best score\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    author_names=grid_search.best_estimator_.named_steps['clf'].classes_\n",
    "\n",
    "    for param_name in sorted(params.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        ScoreSummaryByModelParams.append([comment,grid_search.best_score_,\"\\t%s: %r\" % (param_name, best_parameters[param_name])]) \n",
    "    return (author_predicted,author_predicted_b,author_test_b,author_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "d4d048d1-9119-0e05-53f2-97fa80836fb4"
   },
   "outputs": [],
   "source": [
    "f2_union=FeatureUnion(\n",
    "        transformer_list=[\n",
    "            # Pipeline for pulling char features  from the text\n",
    "            ('char', Pipeline([\n",
    "                ('tfidf',     TfidfVectorizer(analyzer='char',ngram_range=(1, 5))),\n",
    "            ])),\n",
    "            # Pipeline for pulling stememd word features from the text\n",
    "            # ('text', Pipeline([\n",
    "            #     ('tfidf',    TfidfVectorizer(analyzer='word',tokenizer= text_process,ngram_range=(1, 1))),\n",
    "            # ])),        \n",
    "\n",
    "        ],\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_cell_guid": "e7112f9f-9016-34e8-6787-abb3e15a384e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best score: 0.881\n",
      "Best parameters set:\n",
      "\tclf__C: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "#LinearSVC\n",
    "p = {'clf__C': (1,0.1,0.01,0.001,0.0001)}\n",
    "(author_predicted,author_predicted_b, author_test_b,author_names)=ModelParamsEvaluation(f2_union,LinearSVC(),p,'LinearSVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "727657e9-04cb-9b50-e705-aaa6b54d4587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     AdamSavage       0.78      0.85      0.81       182\n",
      "    BarackObama       0.85      0.94      0.89       180\n",
      "    DonaldTrump       0.90      0.85      0.87       212\n",
      "FiveThirtyEight       0.99      1.00      0.99       198\n",
      " HillaryClinton       0.90      0.83      0.87       216\n",
      "  KimKardashian       0.93      0.93      0.93       199\n",
      "           NASA       0.93      0.95      0.94       194\n",
      " RichardDawkins       0.86      0.85      0.86       204\n",
      "     ScottKelly       0.92      0.90      0.91       204\n",
      "  deGrasseTyson       0.87      0.83      0.85       210\n",
      "        various       1.00      1.00      1.00       201\n",
      "\n",
      "      micro avg       0.90      0.90      0.90      2200\n",
      "      macro avg       0.90      0.90      0.90      2200\n",
      "   weighted avg       0.90      0.90      0.90      2200\n",
      "    samples avg       0.90      0.90      0.90      2200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PredictionEvaluation(author_predicted_b, author_test_b,author_names,'LinearSVC')"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 6,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
