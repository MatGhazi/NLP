{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6b96aa9-9e65-4a58-977f-d578abbcac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import os\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9828c87-b9f8-42e6-b261-b741c0835abe",
   "metadata": {
    "_cell_guid": "4931abf3-141e-afea-559c-01560cde768c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '10460KDNuggetsTweets.csv',\n",
       " 'AdamSavageTweets.csv',\n",
       " 'AllTweets.csv',\n",
       " 'BarackObama.csv',\n",
       " 'DonaldTrump2014-01-01To2016-10-14Tweets.csv',\n",
       " 'DonaldTrumpTweets.csv',\n",
       " 'FiveThirtyEightTweets.csv',\n",
       " 'HillaryClinton2014-01-01To2016-10-14Tweets.csv',\n",
       " 'HillaryClintonTweets.csv',\n",
       " 'KimKardashianTweets.csv',\n",
       " 'NeildeGrasseTysonTweets.csv',\n",
       " 'RichardDawkins.csv',\n",
       " 'ScottKelly.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the path to the folder containing CSV files\n",
    "folder_path = 'tweets/'\n",
    "os.listdir(folder_path)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef757ca-165f-4c08-8452-2bbc786e18f7",
   "metadata": {
    "_cell_guid": "4931abf3-141e-afea-559c-01560cde768c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>retweet</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Oct 4</td>\n",
       "      <td>783396985093193728</td>\n",
       "      <td>/missyscheng/status/783396985093193728</td>\n",
       "      <td>False</td>\n",
       "      <td>#DataScience Basics: #DataMining vs. #Statisti...</td>\n",
       "      <td>various</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Oct 4</td>\n",
       "      <td>783381842024103936</td>\n",
       "      <td>/EXASOLAG/status/783381842024103936</td>\n",
       "      <td>False</td>\n",
       "      <td>How to Become a #Data Scientist – Part 1: http...</td>\n",
       "      <td>various</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Oct 4</td>\n",
       "      <td>783433625723252736</td>\n",
       "      <td>/TarasNovak/status/783433625723252736</td>\n",
       "      <td>False</td>\n",
       "      <td>@jesterxl @kdnuggets or just go with @tableau :)</td>\n",
       "      <td>various</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Oct 4</td>\n",
       "      <td>783428740453982208</td>\n",
       "      <td>/kdnuggets/status/783428740453982208</td>\n",
       "      <td>False</td>\n",
       "      <td>#Boston U. Online MS in Applied #Business #Ana...</td>\n",
       "      <td>various</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1h1 hour ago</td>\n",
       "      <td>787052623291641856</td>\n",
       "      <td>/kdnuggets/status/787052623291641856</td>\n",
       "      <td>False</td>\n",
       "      <td>#ICYMI Still Searching for ROI in #BigData Ana...</td>\n",
       "      <td>various</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173030</th>\n",
       "      <td>1214</td>\n",
       "      <td>24 Aug 2009</td>\n",
       "      <td>3506949420</td>\n",
       "      <td>/StationCDRKelly/status/3506949420</td>\n",
       "      <td>False</td>\n",
       "      <td>@karen4jazz thanks!</td>\n",
       "      <td>ScottKelly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173031</th>\n",
       "      <td>1215</td>\n",
       "      <td>23 Aug 2009</td>\n",
       "      <td>3505850138</td>\n",
       "      <td>/StationCDRKelly/status/3505850138</td>\n",
       "      <td>False</td>\n",
       "      <td>The HARDEST thing about this ISS training is h...</td>\n",
       "      <td>ScottKelly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173032</th>\n",
       "      <td>1216</td>\n",
       "      <td>23 Aug 2009</td>\n",
       "      <td>3500803828</td>\n",
       "      <td>/StationCDRKelly/status/3500803828</td>\n",
       "      <td>False</td>\n",
       "      <td>Eating breakfast at the Okura Frontier Hotel i...</td>\n",
       "      <td>ScottKelly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173033</th>\n",
       "      <td>1217</td>\n",
       "      <td>23 Aug 2009</td>\n",
       "      <td>3488056654</td>\n",
       "      <td>/StationCDRKelly/status/3488056654</td>\n",
       "      <td>False</td>\n",
       "      <td>I think you will find the comparison (and cont...</td>\n",
       "      <td>ScottKelly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173034</th>\n",
       "      <td>1218</td>\n",
       "      <td>23 Aug 2009</td>\n",
       "      <td>3488038099</td>\n",
       "      <td>/StationCDRKelly/status/3488038099</td>\n",
       "      <td>False</td>\n",
       "      <td>My first attempt at twittering. in Japan for r...</td>\n",
       "      <td>ScottKelly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173035 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0          date                  id  \\\n",
       "0                0         Oct 4  783396985093193728   \n",
       "1                1         Oct 4  783381842024103936   \n",
       "2                2         Oct 4  783433625723252736   \n",
       "3                3         Oct 4  783428740453982208   \n",
       "4                4  1h1 hour ago  787052623291641856   \n",
       "...            ...           ...                 ...   \n",
       "173030        1214   24 Aug 2009          3506949420   \n",
       "173031        1215   23 Aug 2009          3505850138   \n",
       "173032        1216   23 Aug 2009          3500803828   \n",
       "173033        1217   23 Aug 2009          3488056654   \n",
       "173034        1218   23 Aug 2009          3488038099   \n",
       "\n",
       "                                          link  retweet  \\\n",
       "0       /missyscheng/status/783396985093193728    False   \n",
       "1          /EXASOLAG/status/783381842024103936    False   \n",
       "2        /TarasNovak/status/783433625723252736    False   \n",
       "3         /kdnuggets/status/783428740453982208    False   \n",
       "4         /kdnuggets/status/787052623291641856    False   \n",
       "...                                        ...      ...   \n",
       "173030      /StationCDRKelly/status/3506949420    False   \n",
       "173031      /StationCDRKelly/status/3505850138    False   \n",
       "173032      /StationCDRKelly/status/3500803828    False   \n",
       "173033      /StationCDRKelly/status/3488056654    False   \n",
       "173034      /StationCDRKelly/status/3488038099    False   \n",
       "\n",
       "                                                     text      author  \\\n",
       "0       #DataScience Basics: #DataMining vs. #Statisti...     various   \n",
       "1       How to Become a #Data Scientist – Part 1: http...     various   \n",
       "2        @jesterxl @kdnuggets or just go with @tableau :)     various   \n",
       "3       #Boston U. Online MS in Applied #Business #Ana...     various   \n",
       "4       #ICYMI Still Searching for ROI in #BigData Ana...     various   \n",
       "...                                                   ...         ...   \n",
       "173030                                @karen4jazz thanks!  ScottKelly   \n",
       "173031  The HARDEST thing about this ISS training is h...  ScottKelly   \n",
       "173032  Eating breakfast at the Okura Frontier Hotel i...  ScottKelly   \n",
       "173033  I think you will find the comparison (and cont...  ScottKelly   \n",
       "173034  My first attempt at twittering. in Japan for r...  ScottKelly   \n",
       "\n",
       "        Unnamed: 0.1  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  \n",
       "...              ...  \n",
       "173030           NaN  \n",
       "173031           NaN  \n",
       "173032           NaN  \n",
       "173033           NaN  \n",
       "173034           NaN  \n",
       "\n",
       "[173035 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each CSV file and read it into a DataFrame\n",
    "for csv_file in csv_files:\n",
    "    csv_file_path = os.path.join(folder_path, csv_file)\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Print the combined DataFrame\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b1d204-da12-4146-b65b-d75cceb96b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# data = pd.read_csv('blogtext_short.csv')\n",
    "# data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67260494-d013-42c9-9e8e-120dd3dca6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41362</th>\n",
       "      <td>#Python and R are now neck to neck in the late...</td>\n",
       "      <td>various</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41167</th>\n",
       "      <td>Whitepaper: The Journey to #OpenDataScience ht...</td>\n",
       "      <td>various</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45178</th>\n",
       "      <td>#DeepLearning in #Healthcare Part 1: Opportuni...</td>\n",
       "      <td>various</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39488</th>\n",
       "      <td>RT  RT @kdnuggets JupyterLab: the next generat...</td>\n",
       "      <td>various</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36442</th>\n",
       "      <td>Top Algorithms and Methods Used by Data Scient...</td>\n",
       "      <td>various</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169130</th>\n",
       "      <td>Sam says Hamas publicly says they'd like to ki...</td>\n",
       "      <td>RichardDawkins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98753</th>\n",
       "      <td>This crowd brought their children to watch ISI...</td>\n",
       "      <td>RichardDawkins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168669</th>\n",
       "      <td>Wonderful conversation with @NeilTyson in that...</td>\n",
       "      <td>RichardDawkins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169495</th>\n",
       "      <td>\"My wife and I join Xs the world over celebrat...</td>\n",
       "      <td>RichardDawkins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103046</th>\n",
       "      <td>'Astronomers find loads of ice on big asteroid...</td>\n",
       "      <td>RichardDawkins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text          author\n",
       "41362   #Python and R are now neck to neck in the late...         various\n",
       "41167   Whitepaper: The Journey to #OpenDataScience ht...         various\n",
       "45178   #DeepLearning in #Healthcare Part 1: Opportuni...         various\n",
       "39488   RT  RT @kdnuggets JupyterLab: the next generat...         various\n",
       "36442   Top Algorithms and Methods Used by Data Scient...         various\n",
       "...                                                   ...             ...\n",
       "169130  Sam says Hamas publicly says they'd like to ki...  RichardDawkins\n",
       "98753   This crowd brought their children to watch ISI...  RichardDawkins\n",
       "168669  Wonderful conversation with @NeilTyson in that...  RichardDawkins\n",
       "169495  \"My wife and I join Xs the world over celebrat...  RichardDawkins\n",
       "103046  'Astronomers find loads of ice on big asteroid...  RichardDawkins\n",
       "\n",
       "[11000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary to store the sampled records for each author\n",
    "sampled_data = {}\n",
    "\n",
    "# get a list of unique author labels\n",
    "authors = combined_df['author'].unique()\n",
    "\n",
    "# loop through each author and sample 1000 records of text\n",
    "for author in authors:\n",
    "    author_data = combined_df[combined_df['author'] == author][['text','author']].sample(n=1000)\n",
    "    sampled_data[author] = author_data\n",
    "\n",
    "# combine the sampled data for each author into a single dataframe\n",
    "df = pd.concat(sampled_data.values())\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "241bbc49-965b-4474-833e-002a181aecdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "various            1000\n",
       "AdamSavage         1000\n",
       "NASA               1000\n",
       "BarackObama        1000\n",
       "DonaldTrump        1000\n",
       "FiveThirtyEight    1000\n",
       "HillaryClinton     1000\n",
       "KimKardashian      1000\n",
       "deGrasseTyson      1000\n",
       "ScottKelly         1000\n",
       "RichardDawkins     1000\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce63e148-63c3-4743-bf92-a1e4d5a34e61",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25cff848-d455-4948-93c6-ac378204dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['author']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7c3ec01-2ebc-466c-8450-84e81ba21e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and preprocess text data\n",
    "def clean_text(text):\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenize into words\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Stemming and Lemmatization\n",
    "    # stemmer = PorterStemmer()\n",
    "    # lemmatizer = WordNetLemmatizer()\n",
    "    # words_stem = [stemmer.stem(word) for word in words]\n",
    "    # words_lem = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Normalization\n",
    "    text_clean = ' '.join(words)\n",
    "    text_clean = re.sub('\\s+', ' ', text_clean).strip()\n",
    "\n",
    "    return text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0ac4fb4-80be-4951-9632-fafceee3329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X1_train = X_train.apply(clean_text)\n",
    "X1_test = X_test.apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f567c6-f473-4a79-97bb-b03b15f9b5ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature extraction methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65a2a66-189d-4996-a9db-57e3eea8377d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bag of Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e24c1e01-4c08-46a3-8cf7-7b25ad6866dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_word(X_train, X_test):\n",
    "    # Extract bag of words features\n",
    "    \n",
    "    vectorizer = CountVectorizer(stop_words='english')\n",
    "    train_features = vectorizer.fit_transform(X_train)\n",
    "    test_features = vectorizer.transform(X_test)\n",
    "    \n",
    "    return train_features, test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897faa71-192a-4b70-a633-b30cb3014e4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7da7c73e-1a63-4572-8b85-707f13cce1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(X_train, X_test):\n",
    "\n",
    "    # Create a TfidfVectorizer object to extract features\n",
    "    tfidf = TfidfVectorizer()\n",
    "\n",
    "    # fit and Transform the training and testing data using the vectorizer\n",
    "    train_features =  tfidf.fit_transform(X_train)\n",
    "    test_features = tfidf.transform(X_test)\n",
    "    \n",
    "    return train_features, test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bde874-5ee9-4349-adaf-139fa3da94ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "### N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db8a8bbe-ae44-4f95-be2e-7c379b61d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram(X_train, X_test):\n",
    "    \n",
    "    tfidf = TfidfVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "    # fit and Transform the training and testing data using the vectorizer\n",
    "    train_features =  tfidf.fit_transform(X_train)\n",
    "    test_features = tfidf.transform(X_test)\n",
    "    \n",
    "    return train_features, test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d24730-d53a-4518-9c7d-868f12e3896c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee18f565-83d2-4662-b95a-efe29af040b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fb40a31-f478-49ca-8756-13cb39b74fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(train_features, y_train, test_features, y_test):\n",
    "\n",
    "    # Train Random Forest classifier\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(train_features, y_train)\n",
    "\n",
    "    # Predict on test set and measure accuracy\n",
    "    y_pred = clf.predict(test_features)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    PredictionEvaluation(y_test, y_pred)\n",
    "    \n",
    "    # return (f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be9117f-6a88-4241-9a54-dd185c272c7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e474a349-99b7-4ef2-90e7-8a68f95a095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_Regression(train_features, y_train, test_features, y_test):\n",
    "\n",
    "    # Create a Logistic Regression model\n",
    "    lr = LogisticRegression()\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    lr.fit(train_features, y_train)\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    predictions = lr.predict(test_features)\n",
    "\n",
    "    # Calculate the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    PredictionEvaluation(y_test, predictions)\n",
    "    \n",
    "    # return (f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8412d170-bf73-453e-84b9-241985bf50e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "90267592-5015-4146-8736-80c3e33c76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayes(train_features, y_train, test_features, y_test):\n",
    "    params = {'alpha': [0.5, 1, 2, 5, 10]}\n",
    "    nb = MultinomialNB()\n",
    "    nb_gs = GridSearchCV(nb, params, cv=5)\n",
    "    nb_gs.fit(train_features, y_train)\n",
    "    print(\"Best parameters: \", nb_gs.best_params_)\n",
    "    y_pred = nb_gs.predict(test_features)\n",
    "    \n",
    "    # author_names=nb_gs.best_estimator_.named_steps['clf'].classes_\n",
    "    # print(\"Accuracy score: \", accuracy_score(y_test, y_pred))\n",
    "    PredictionEvaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca7e213-ddab-4dfd-a770-2965ed5ccc74",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e3a8de3-e0e1-496a-bf34-b1fe3b091fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f7932199-aec2-4043-9477-13408cdf4542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictionEvaluation(author_test_b,author_predicted_b):\n",
    "# def PredictionEvaluation(author_test_b,author_predicted_b):\n",
    "    Accuracy=accuracy_score(author_test_b,author_predicted_b)\n",
    "    print ('Accuracy', Accuracy)\n",
    "    Recall=recall_score(author_test_b, author_predicted_b, average= 'macro')\n",
    "    print ('Recall', Recall)\n",
    "    Precision=precision_score(author_test_b, author_predicted_b, average= 'macro')\n",
    "    print ('Precision', Precision)\n",
    "    F1=f1_score(author_test_b, author_predicted_b, average= 'macro')\n",
    "    print ('F1' , F1)\n",
    "    # ScoreSummaryByModel.append([Accuracy,Recall,Precision,F1,comment])\n",
    "    print(classification_report(author_test_b, author_predicted_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eccfacac-6038-47e2-bf0b-7d2dfaf605b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8322727272727273\n",
      "Recall 0.8313237548754171\n",
      "Precision 0.8342430916765334\n",
      "F1 0.832296102726934\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     AdamSavage       0.72      0.71      0.71       202\n",
      "    BarackObama       0.89      0.81      0.85       214\n",
      "    DonaldTrump       0.74      0.76      0.75       197\n",
      "FiveThirtyEight       1.00      0.98      0.99       204\n",
      " HillaryClinton       0.80      0.85      0.82       210\n",
      "  KimKardashian       0.76      0.77      0.76       178\n",
      "           NASA       0.91      0.85      0.88       184\n",
      " RichardDawkins       0.79      0.82      0.80       213\n",
      "     ScottKelly       0.88      0.86      0.87       194\n",
      "  deGrasseTyson       0.73      0.77      0.75       198\n",
      "        various       0.98      0.97      0.97       206\n",
      "\n",
      "       accuracy                           0.83      2200\n",
      "      macro avg       0.83      0.83      0.83      2200\n",
      "   weighted avg       0.84      0.83      0.83      2200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.83'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, test_features = tf_idf(X_train, X_test)\n",
    "# random_forest(train_features, y_train, test_features, y_test)\n",
    "Logistic_Regression(train_features, y_train, test_features, y_test)\n",
    "# Naive_Bayes(train_features, y_train, test_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9dd1d12c-3930-4dc6-afbf-7fa7906d81e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_features, test_features = bag_of_word(X_train, X_test)\n",
    "# random_forest(train_features, y_train, test_features, y_test)\n",
    "# Logistic_Regression(train_features, y_train, test_features, y_test)\n",
    "# Naive_Bayes(train_features, y_train, test_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e9a1c041-d73e-4b98-8a2c-938dddd51858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'alpha': 0.5}\n",
      "Accuracy 0.8445454545454546\n",
      "Recall 0.8436307791485124\n",
      "Precision 0.8464279705633722\n",
      "F1 0.8432887792454359\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     AdamSavage       0.82      0.72      0.77       202\n",
      "    BarackObama       0.76      0.91      0.83       214\n",
      "    DonaldTrump       0.72      0.76      0.74       197\n",
      "FiveThirtyEight       0.97      0.97      0.97       204\n",
      " HillaryClinton       0.83      0.83      0.83       210\n",
      "  KimKardashian       0.86      0.75      0.80       178\n",
      "           NASA       0.85      0.96      0.90       184\n",
      " RichardDawkins       0.85      0.81      0.83       213\n",
      "     ScottKelly       0.88      0.87      0.88       194\n",
      "  deGrasseTyson       0.80      0.74      0.77       198\n",
      "        various       0.97      0.97      0.97       206\n",
      "\n",
      "       accuracy                           0.84      2200\n",
      "      macro avg       0.85      0.84      0.84      2200\n",
      "   weighted avg       0.85      0.84      0.84      2200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_features, test_features = n_gram(X_train, X_test)\n",
    "# random_forest(train_features, y_train, test_features, y_test)\n",
    "# Logistic_Regression(train_features, y_train, test_features, y_test)\n",
    "Naive_Bayes(train_features, y_train, test_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb69c3-2680-4132-8a59-a6b2f7bf54d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
